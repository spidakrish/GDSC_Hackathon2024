# Importing the OpenAI library, which is essential to make API calls to OpenAI models
import openai

# Setting the API key that authenticates requests to the OpenAI API. 
# WARNING: Never hard-code your API keys in production code or public repositories.
# A better practice would be to use environment variables or a config file that is not pushed to GitHub.
openai.api_key = "your-api-key-here"

# Define a function to interact with the OpenAI GPT model
def chat_with_gpt(prompt):
    """
    This function takes a user input 'prompt', sends it to the GPT model using OpenAI's API,
    and returns the model's response.
    
    Parameters:
        prompt (str): The input question or command from the user.
    
    Returns:
        str: The response generated by the GPT model.
    """
    try:
        # The OpenAI ChatCompletion API call to GPT model
        response = openai.ChatCompletion.create(
            model="gpt-3.5-turbo",  # The model used for generating the response. It could be GPT-3.5 or GPT-4 based on access.
            messages=[
                # A system message that defines the assistant's behavior. In this case, the assistant is helpful.
                {"role": "system", "content": "You are a helpful assistant."},
                # A user message that contains the input from the user.
                {"role": "user", "content": prompt}
            ],
            max_tokens=150,  # Limits the length of the response (in tokens) to avoid excessive responses.
            temperature=0.7   # Adjusts the creativity of the model. 0.7 means balanced creativity vs. coherence.
        )
        
        # Returning the response content from GPT. The message content is extracted from the response.
        return response['choices'][0]['message']['content'].strip()
    
    except openai.error.OpenAIError as e:
        # If an error occurs (like a bad API call), the error is caught and a message is returned.
        return f"An error occurred: {e}"

# Define the main function that runs the chat interface
def main():
    """
    This is the main function that sets up the command-line chat interface.
    It continuously takes user input, sends it to GPT, and prints the response until the user quits.
    """
    # Print a welcome message when the chat starts
    print("Welcome to your GPT-powered assistant in the terminal!")
    
    # Infinite loop to keep asking the user for input
    while True:
        # Accept input from the user
        prompt = input("You: ")
        
        # If the user types 'exit' or 'quit', end the program
        if prompt.lower() in ["exit", "quit"]:
            print("Exiting the assistant. Goodbye!")
            break
        
        # Call the chat_with_gpt function with the user's input and get the response
        response = chat_with_gpt(prompt)
        
        # Print GPT's response to the console
        print(f"GPT: {response}")

# Ensure that the main function is called only when the script is executed directly, 
# and not when imported as a module in another file.
if __name__ == "__main__":
    main()
